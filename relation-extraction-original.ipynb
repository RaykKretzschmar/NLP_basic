{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from spacy.matcher import Matcher\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "from tqdm import autonotebook as tqdm\n",
    "from itertools import combinations\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./data/teaching-dataset\")\n",
    "with (data_dir / \"relation_extraction_text_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"input.txt\") as f:\n",
    "        sentences = [\n",
    "            sentence.split(\"\\n\") for sentence in f.read().decode(\"utf-8\").split(\"\\n\\n\")\n",
    "        ]\n",
    "with (data_dir / \"relation_extraction_references_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"references.txt\") as f:\n",
    "        labels = []\n",
    "        for line in f.read().decode(\"utf-8\").split(\"\\n\"):\n",
    "            relations = []\n",
    "            for relation in re.finditer(r\"\\(\\((\\d+),(\\d+)\\),\\((\\d+),(\\d+)\\)\\)\", line):\n",
    "                relation = (\n",
    "                    (int(relation.group(1)), int(relation.group(2))),\n",
    "                    (int(relation.group(3)), int(relation.group(4))),\n",
    "                )\n",
    "                relations.append(relation)\n",
    "            labels.append(relations)\n",
    "assert len(sentences) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(Doc(nlp.vocab, words=sentences[0]))\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAUSAL_CUES = [\"because\", \"since\", \"due\", \"cause\", \"lead\", \"result\", \"effect\"]\n",
    "MATCHER = Matcher(nlp.vocab)\n",
    "# sentence classification\n",
    "MATCHER.add(\"CAUSAL\", [[{\"LEMMA\": cue}] for cue in CAUSAL_CUES])\n",
    "# span extraction\n",
    "MATCHER.add(\n",
    "    \"EVENT\",\n",
    "    [\n",
    "        [\n",
    "            {\"POS\": {\"IN\": [\"NOUN\", \"PROPN\", \"ADJ\"]}, \"OP\": \"+\"},\n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "# relation classification\n",
    "# https://stackoverflow.com/questions/74528441/detect-passive-or-active-sentence-from-text\n",
    "MATCHER.add(\n",
    "    \"PASSIVE\",\n",
    "    [\n",
    "        [\n",
    "            {\"DEP\": \"nsubjpass\"},\n",
    "            {\"DEP\": \"aux\", \"OP\": \"*\"},\n",
    "            {\"DEP\": \"auxpass\"},\n",
    "            {\"TAG\": \"VBN\"},\n",
    "        ],\n",
    "        [\n",
    "            {\"DEP\": \"nsubjpass\"},\n",
    "            {\"DEP\": \"aux\", \"OP\": \"*\"},\n",
    "            {\"DEP\": \"auxpass\"},\n",
    "            {\"TAG\": \"VBZ\"},\n",
    "        ],\n",
    "        [\n",
    "            {\"DEP\": \"nsubjpass\"},\n",
    "            {\"DEP\": \"aux\", \"OP\": \"*\"},\n",
    "            {\"DEP\": \"auxpass\"},\n",
    "            {\"TAG\": \"RB\"},\n",
    "            {\"TAG\": \"VBN\"},\n",
    "        ],\n",
    "    ],\n",
    ")\n",
    "\n",
    "def in_the_middle_or_overlap(ent_1, ent_2, match_span):\n",
    "    if ent_1.start > ent_2.start:\n",
    "        ent_1, ent_2 = ent_2, ent_1\n",
    "    return ent_1.end < match_span.start < ent_2.start or ent_1.end < match_span.end < ent_2.start\n",
    "\n",
    "\n",
    "def match(doc):\n",
    "    raw_matches = MATCHER(doc)\n",
    "    matches = {\"EVENT\": [], \"CAUSAL\": [], \"PASSIVE\": [], \"ACTIVE\": []}\n",
    "    for match_id, start, end in raw_matches:\n",
    "        matches[nlp.vocab.strings[match_id]].append(doc[start:end])\n",
    "    matches[\"EVENT\"] = spacy.util.filter_spans(matches[\"EVENT\"])\n",
    "    return matches\n",
    "\n",
    "def predict(doc):\n",
    "    matches = match(doc)\n",
    "    out = []\n",
    "    if not matches[\"CAUSAL\"]:\n",
    "        return out\n",
    "    for event_1, event_2 in combinations(matches[\"EVENT\"], 2):\n",
    "        for passive_match in matches[\"PASSIVE\"]:\n",
    "            if in_the_middle_or_overlap(event_1, event_2, passive_match):\n",
    "                out.append(((event_2.start, event_2.end), (event_1.start, event_1.end)))\n",
    "                break\n",
    "        else:\n",
    "            out.append(((event_1.start, event_1.end), (event_2.start, event_2.end)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "doc = nlp(Doc(nlp.vocab, words=sentences[idx]))\n",
    "pred = predict(doc)\n",
    "print(doc)\n",
    "print(\"Ground truth:\")\n",
    "for cause, effect in labels[idx]:\n",
    "    print(\"\\t{} -> {}\".format(doc[cause[0]:cause[1]], doc[effect[0]:effect[1]]))\n",
    "print(\"Predictions:\")\n",
    "for cause, effect in pred:\n",
    "    print(\"\\t{} -> {}\".format(doc[cause[0]:cause[1]], doc[effect[0]:effect[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for sentence in tqdm.tqdm(sentences):\n",
    "    doc = nlp(Doc(nlp.vocab, words=sentence))\n",
    "    predictions.append(predict(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(ref_event, pred_event):\n",
    "    return max(ref_event[0], pred_event[0]) <= min(ref_event[1], pred_event[1])\n",
    "\n",
    "\n",
    "def evaluate_pair(reference, prediction):\n",
    "    ref_cause, ref_effect = reference\n",
    "    pred_cause, pred_effect = prediction\n",
    "    if ref_cause == pred_cause and ref_effect == pred_effect:\n",
    "        return 1\n",
    "    elif overlap(ref_cause, pred_cause) and overlap(ref_effect, pred_effect):\n",
    "        return 0.5\n",
    "    return 0\n",
    "\n",
    "def precision(tp, fp):\n",
    "    if not tp:\n",
    "        return 0\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(tp, fn):\n",
    "    if not tp:\n",
    "        return 0\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1(tp, fp, fn):\n",
    "    if not tp:\n",
    "        return 0\n",
    "    return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "def evaluate(references, predictions):\n",
    "    tps, fps, fns = [], [], []\n",
    "    for reference, prediction in zip(references, predictions):\n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        remaining_references = set(reference)\n",
    "        for pred in prediction:\n",
    "            for ref in remaining_references:\n",
    "                score = evaluate_pair(ref, pred)\n",
    "                if score:\n",
    "                    tp += score\n",
    "                    remaining_references.remove(ref)\n",
    "                    break\n",
    "            else:\n",
    "                fp += 1\n",
    "        fn += len(remaining_references)\n",
    "        tps.append(tp)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "\n",
    "    macro_prec = sum([precision(tp, fp) for tp, fp in zip(tps, fps)]) / len(tps)\n",
    "    macro_rec = sum([recall(tp, fn) for tp, fn in zip(tps, fns)]) / len(tps)\n",
    "    macro_f1 = sum([f1(tp, fp, fn) for tp, fp, fn in zip(tps, fps, fns)]) / len(tps)\n",
    "    micro_prec = precision(sum(tps), sum(fps))\n",
    "    micro_rec = recall(sum(tps), sum(fns))\n",
    "    micro_f1 = f1(sum(tps), sum(fps), sum(fns))\n",
    "    return {\n",
    "        \"macro\": {\"precision\": macro_prec, \"recall\": macro_rec, \"f1\": macro_f1},\n",
    "        \"micro\": {\"precision\": micro_prec, \"recall\": micro_rec, \"f1\": micro_f1},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./data/teaching-dataset\")\n",
    "with (data_dir / \"relation_extraction_text_test.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"input.txt\") as f:\n",
    "        test_sentences = [\n",
    "            sentence.split(\"\\n\") for sentence in f.read().decode(\"utf-8\").split(\"\\n\\n\")\n",
    "        ]\n",
    "\n",
    "test_predictions = []\n",
    "for sentence in tqdm.tqdm(test_sentences):\n",
    "    doc = nlp(Doc(nlp.vocab, words=sentence))\n",
    "    test_predictions.append(predict(doc))\n",
    "\n",
    "with open(\"predictions.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(\",\".join(str(relation) for relation in prediction) for prediction in test_predictions).replace(\" \", \"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
