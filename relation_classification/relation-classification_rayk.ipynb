{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc, SpanGroup\n",
    "from spacy.matcher import Matcher\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "from tqdm import autonotebook as tqdm\n",
    "from spacy.training import biluo_tags_to_spans\n",
    "import iobes\n",
    "import re\n",
    "from itertools import combinations\n",
    "import openai\n",
    "import os\n",
    "import time\n",
    "\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/teaching-dataset\")\n",
    "with (data_dir / \"relation_classification_text_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"input.txt\") as f:\n",
    "        sentences = [\n",
    "            sentence.split(\"\\n\") for sentence in f.read().decode(\"utf-8\").split(\"\\n\\n\")\n",
    "        ]\n",
    "with (data_dir / \"relation_classification_references_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"references.txt\") as f:\n",
    "        labels = []\n",
    "        for line in f.read().decode(\"utf-8\").split(\"\\n\"):\n",
    "            relations = []\n",
    "            for relation in re.finditer(r\"\\(\\((\\d+),(\\d+)\\),\\((\\d+),(\\d+)\\)\\)\", line):\n",
    "                relation = (\n",
    "                    (int(relation.group(1)), int(relation.group(2))),\n",
    "                    (int(relation.group(3)), int(relation.group(4))),\n",
    "                )\n",
    "                relations.append(relation)\n",
    "            labels.append(relations)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence(sentence):\n",
    "    words = []\n",
    "    tags = []\n",
    "    for item in sentence:\n",
    "        word, tag = item.split(\" \")\n",
    "        words.append(word)\n",
    "        tags.append(tag)\n",
    "    doc = Doc(nlp.vocab, words=words)\n",
    "    doc = nlp(doc)\n",
    "    tags = iobes.bio_to_bilou(tags)\n",
    "    doc.ents = biluo_tags_to_spans(doc, tags)\n",
    "    return doc\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_tags_and_tokens_for_sentences(sentences):\n",
    "#     for sentence in sentences:\n",
    "#         doc = parse_sentence(sentence)\n",
    "#         for token in doc:\n",
    "#             print(f\"{token.text}, {token.ents}, POS-Tag: {token.pos_}, Dep-Tag: {token.dep_}\")\n",
    "#         print(\"\\n\")\n",
    "# print_tags_and_tokens_for_sentences(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_spans(sentences):\n",
    "    spans_per_sentence = []\n",
    "    spans = []\n",
    "    for sentence_index in range(len(sentences)):\n",
    "        span_start = -1\n",
    "        span_end = -1\n",
    "        for word_index in range(len(sentences[sentence_index])):\n",
    "\n",
    "            word, tag = sentences[sentence_index][word_index].split(' ')\n",
    "            if tag == 'B-EVENT':\n",
    "                span_start = word_index\n",
    "                for end_index in range(span_start, len(sentences[sentence_index])):\n",
    "                    word, tag = sentences[sentence_index][end_index].split(' ')\n",
    "                    if tag == 'O':\n",
    "                        span_end = end_index\n",
    "                        spans.append((span_start, span_end))\n",
    "                        break\n",
    "            span_start = -1\n",
    "            span_end = -1\n",
    "        spans_per_sentence.append(spans)\n",
    "        spans = []\n",
    "    return spans_per_sentence\n",
    "    \n",
    "spans_per_sentence = gen_spans(sentences)\n",
    "print(spans_per_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(sentences, spans_per_sentence):\n",
    "predictions = []\n",
    "for sentence_index in range(len(sentences)):\n",
    "    sentence_predictions = []\n",
    "    doc = parse_sentence(sentences[sentence_index])\n",
    "    doc.ents\n",
    "\n",
    "    for entity_index1 in range(len(doc.ents)):\n",
    "        for entity_index2 in range(entity_index1+1, len(doc.ents)):\n",
    "            prediction = []\n",
    "            prompt = f'Answer with \"1\" if \"{doc.ents[entity_index1]}\" is the cause for \"{doc.ents[entity_index2]}\". Answer with \"2\" if \"{doc.ents[entity_index2]}\" is the cause for \"{doc.ents[entity_index1]}\". Answer with \"0\" if there are no causal relations between the two. Answer only with that one word.'\n",
    "            print(prompt)\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt},],\n",
    "                temperature= 0,\n",
    "                max_tokens = 200\n",
    "                )\n",
    "        \n",
    "            message = response.choices[0].message.content\n",
    "            print(doc)\n",
    "            print(message)\n",
    "            time.sleep(2)\n",
    "    \n",
    "\n",
    "            if '1' == message:\n",
    "                prediction.append((spans_per_sentence[sentence_index][entity_index1], spans_per_sentence[sentence_index][entity_index2]))\n",
    "            elif '2' == message:\n",
    "                prediction.append((spans_per_sentence[sentence_index][entity_index2], spans_per_sentence[sentence_index][entity_index1]))\n",
    "            elif '0' == message:\n",
    "                print(\"No Causal Prediction\")\n",
    "            else:\n",
    "                print(\"Wrong output\")\n",
    "\n",
    "            sentence_predictions.append(prediction)\n",
    "            print(sentence_index, '/', len(sentences))\n",
    "\n",
    "    predictions.append(sentence_predictions)\n",
    "\n",
    "    # return predictions\n",
    "\n",
    "# predictions = predict(sentences, spans_per_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, references, micro_avg=True):\n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    for prediction, reference in zip(predictions, references):\n",
    "        tp.append(len(set(prediction) & set(reference)))\n",
    "        fp.append(len(set(prediction) - set(reference)))\n",
    "        fn.append(len(set(reference) - set(prediction)))\n",
    "    if micro_avg:\n",
    "        tp = [sum(tp)]\n",
    "        fp = [sum(fp)]\n",
    "        fn = [sum(fn)]\n",
    "    precision = [0 if tp[i] == 0 else tp[i] / (tp[i] + fp[i]) for i in range(len(tp))]\n",
    "    recall = [0 if tp[i] == 0 else tp[i] / (tp[i] + fn[i]) for i in range(len(tp))]\n",
    "    f1 = [\n",
    "        0\n",
    "        if precision[i] * recall[i] == 0\n",
    "        else 2 * precision[i] * recall[i] / (precision[i] + recall[i])\n",
    "        for i in range(len(tp))\n",
    "    ]\n",
    "    precision = sum(precision) / len(precision)\n",
    "    recall = sum(recall) / len(recall)\n",
    "    f1 = sum(f1) / len(f1)\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "micro_precision, micro_recall, micro_f1 = evaluate(predictions, labels, True)\n",
    "macro_precision, macro_recall, macro_f1 = evaluate(predictions, labels, False)\n",
    "\n",
    "print(\"Micro Precision: {:.2f}\".format(micro_precision))\n",
    "print(\"Micro Recall: {:.2f}\".format(micro_recall))\n",
    "print(\"Micro F1: {:.2f}\".format(micro_f1))\n",
    "print(\"Macro Precision: {:.2f}\".format(macro_precision))\n",
    "print(\"Macro Recall: {:.2f}\".format(macro_recall))\n",
    "print(\"Macro F1: {:.2f}\".format(macro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(ref_event, pred_event):\n",
    "    return max(ref_event[0], pred_event[0]) <= min(ref_event[1], pred_event[1])\n",
    "\n",
    "\n",
    "def evaluate_pair(reference, prediction):\n",
    "    ref_cause, ref_effect = reference\n",
    "    pred_cause, pred_effect = prediction\n",
    "    if ref_cause == pred_cause and ref_effect == pred_effect:\n",
    "        return 1\n",
    "    elif overlap(ref_cause, pred_cause) and overlap(ref_effect, pred_effect):\n",
    "        return 0.5\n",
    "    return 0\n",
    "\n",
    "def precision(tp, fp):\n",
    "    if not tp:\n",
    "        return 0\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(tp, fn):\n",
    "    if not tp:\n",
    "        return 0\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1(tp, fp, fn):\n",
    "    if not tp:\n",
    "        return 0\n",
    "    return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "def evaluate(references, predictions):\n",
    "    tps, fps, fns = [], [], []\n",
    "    for reference, prediction in zip(references, predictions):\n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        remaining_references = set(reference)\n",
    "        for pred in prediction:\n",
    "            for ref in remaining_references:\n",
    "                score = evaluate_pair(ref, pred)\n",
    "                if score:\n",
    "                    tp += score\n",
    "                    remaining_references.remove(ref)\n",
    "                    break\n",
    "            else:\n",
    "                fp += 1\n",
    "        fn += len(remaining_references)\n",
    "        tps.append(tp)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "\n",
    "    macro_prec = sum([precision(tp, fp) for tp, fp in zip(tps, fps)]) / len(tps)\n",
    "    macro_rec = sum([recall(tp, fn) for tp, fn in zip(tps, fns)]) / len(tps)\n",
    "    macro_f1 = sum([f1(tp, fp, fn) for tp, fp, fn in zip(tps, fps, fns)]) / len(tps)\n",
    "    micro_prec = precision(sum(tps), sum(fps))\n",
    "    micro_rec = recall(sum(tps), sum(fns))\n",
    "    micro_f1 = f1(sum(tps), sum(fps), sum(fns))\n",
    "    return {\n",
    "        \"macro\": {\"precision\": macro_prec, \"recall\": macro_rec, \"f1\": macro_f1},\n",
    "        \"micro\": {\"precision\": micro_prec, \"recall\": micro_rec, \"f1\": micro_f1},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(labels, predictions)\n",
    "\n",
    "# evaluate(labels, [((14, 16), (9, 11))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./data/teaching-dataset\")\n",
    "with (data_dir / \"relation_classification_text_test.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"input.txt\") as f:\n",
    "        test_sentences = [\n",
    "            sentence.split(\"\\n\") for sentence in f.read().decode(\"utf-8\").split(\"\\n\\n\")\n",
    "        ]\n",
    "\n",
    "test_spans_per_sentence = gen_spans(test_sentences)\n",
    "# test_predictions = predict(test_sentences, test_spans_per_sentence)\n",
    "\n",
    "# test_predictions = []\n",
    "# for sentence in tqdm.tqdm(test_sentences):\n",
    "#     doc = nlp(Doc(nlp.vocab, words=sentence))\n",
    "#     test_predictions.append(predict(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = []\n",
    "# for sentence_index in range(len(test_sentences)):\n",
    "#     prediction = []\n",
    "#     doc = parse_sentence(test_sentences[sentence_index])\n",
    "#     doc.ents\n",
    "#     prompt = f'Answer with \"1\" if \"{doc.ents[0]}\" is the cause for \"{doc.ents[1]}\". Answer with \"2\" if \"{doc.ents[1]}\" is the cause for \"{doc.ents[0]}\". Answer with \"0\" if there are no causal relations between the two. Answer only with that one word.'\n",
    "#     print(prompt)\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         messages=[{\"role\": \"system\", \"content\": prompt},],\n",
    "#         temperature= 0,\n",
    "#         max_tokens=200,\n",
    "#         )\n",
    "        \n",
    "#     message = response.choices[0].message.content\n",
    "#     print(doc)\n",
    "#     print(message)\n",
    "#     time.sleep(5)\n",
    "\n",
    "\n",
    "#     if '1' == message:\n",
    "#         prediction.append((test_spans_per_sentence[sentence_index][0], test_spans_per_sentence[sentence_index][1]))\n",
    "#     elif '2' == message:\n",
    "#         prediction.append((test_spans_per_sentence[sentence_index][1], test_spans_per_sentence[sentence_index][0]))\n",
    "#     elif '0' == message:\n",
    "#         print(\"No Causal Prediction\")\n",
    "#     else:\n",
    "#         print(\"Wrong output\")\n",
    "\n",
    "#     test_predictions.append(prediction)\n",
    "#     print(sentence_index+1, '/', len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "for sentence_index in range(len(test_sentences)):\n",
    "    sentence_predictions = []\n",
    "    doc = parse_sentence(test_sentences[sentence_index])\n",
    "    doc.ents\n",
    "\n",
    "    for entity_index1 in range(len(doc.ents)):\n",
    "        for entity_index2 in range(entity_index1+1, len(doc.ents)):\n",
    "            prediction = []\n",
    "            prompt = f'Answer with \"1\" if \"{doc.ents[entity_index1]}\" is the cause for \"{doc.ents[entity_index2]}\". Answer with \"2\" if \"{doc.ents[entity_index2]}\" is the cause for \"{doc.ents[entity_index1]}\". Answer with \"0\" if there are no causal relations between the two. Answer only with that one word.'\n",
    "            print(prompt)\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt},],\n",
    "                temperature= 0,\n",
    "                max_tokens = 200\n",
    "                )\n",
    "        \n",
    "            message = response.choices[0].message.content\n",
    "            print(doc)\n",
    "            print(message)\n",
    "            time.sleep(5)\n",
    "    \n",
    "\n",
    "            if '1' == message:\n",
    "                prediction.append((test_spans_per_sentence[sentence_index][entity_index1], test_spans_per_sentence[sentence_index][entity_index2]))\n",
    "            elif '2' == message:\n",
    "                prediction.append((test_spans_per_sentence[sentence_index][entity_index2], test_spans_per_sentence[sentence_index][entity_index1]))\n",
    "            elif '0' == message:\n",
    "                print(\"No Causal Prediction\")\n",
    "            else:\n",
    "                print(\"Wrong output\")\n",
    "\n",
    "            sentence_predictions.append(prediction)\n",
    "            print(sentence_index, '/', len(test_sentences))\n",
    "\n",
    "    test_predictions.append(sentence_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions.txt\", \"w\") as f:\n",
    "    # f.write(\"\\n\".join(\",\".join(str(relation) for relation in prediction) for prediction in test_predictions).replace(\" \", \"\"))\n",
    "    f.write(\"\\n\".join(\",\".join(str(relation) for sublist in prediction for relation in sublist) for prediction in test_predictions).replace(\" \", \"\").replace(\"[\",\"\").replace(\"]\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple predictions per sentence\n",
    "  \"Macro Precision\": \"0.4721191223742245\",\n",
    "\n",
    "  \"Macro Recall\": \"0.5880952380952381\",\n",
    "\n",
    "  \"Macro F1\": \"0.5085862665868351\",\n",
    "\n",
    "  \"Micro Precision\": \"0.3944223107569721\",\n",
    "\n",
    "  \"Micro Recall\": \"0.6149068322981367\",\n",
    "  \n",
    "  \"Micro F1\": \"0.48058252427184467\"\n",
    "\n",
    "\n",
    "# only one prediction per sentence\n",
    "  \"Macro Precision\": \"0.5612244897959183\",\n",
    "\n",
    "  \"Macro Recall\": \"0.4340136054421769\",\n",
    "\n",
    "  \"Macro F1\": \"0.4687074829931972\",\n",
    "\n",
    "  \"Micro Precision\": \"0.6111111111111112\",\n",
    "\n",
    "  \"Micro Recall\": \"0.3416149068322981\",\n",
    "\n",
    "  \"Micro F1\": \"0.43824701195219123\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
