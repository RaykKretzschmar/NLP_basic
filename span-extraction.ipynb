{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rj/v6gwfj7n3j760s40dxyrf20h0000gn/T/ipykernel_25197/2721346644.py:9: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm import autonotebook as tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval import scheme\n",
    "from tqdm import autonotebook as tqdm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from collections.abc import Iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGULAR DATA IMPORT\n",
    "data_dir = Path(\"./data/teaching-dataset\")\n",
    "with (data_dir / \"span_extraction_text_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"input.txt\") as f:\n",
    "        sentences = [\n",
    "            sentence.split(\"\\n\") for sentence in f.read().decode(\"utf-8\").split(\"\\n\\n\")\n",
    "        ]\n",
    "with (data_dir / \"span_extraction_references_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"references.txt\") as f:\n",
    "        labels = [\n",
    "            sentence.split(\"\\n\") for sentence in f.read().decode(\"utf-8\").split(\"\\n\\n\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS MY METHOD OF DATA IMPORTING (USING VS-CODE CAUSES ISSUES OTHERWISE)\n",
    "parent = Path(os.getcwd()).parent\n",
    "data_dir = Path(os.path.join(parent,\"data/span-detection\"))\n",
    "\n",
    "with (data_dir / \"span_extraction_text_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"input.txt\") as f:\n",
    "        sentences = [\n",
    "            sentence.split(\"\\n\") for sentence in f.read().decode(\"utf-8\").split(\"\\n\\n\")\n",
    "        ]\n",
    "with (data_dir / \"span_extraction_references_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"references.txt\") as f:\n",
    "        labels = [\n",
    "            sentence.split(\"\\n\") for sentence in f.read().decode(\"utf-8\").split(\"\\n\\n\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels =  train_test_split(sentences, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class is_causal_predictor:\n",
    "    def __init__(self, sentences, labels, n=None):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.n = n\n",
    "        self.test_sentences = test_sentences\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "        self.init_words()\n",
    "        if n != None:\n",
    "            self.causal_cues = self.get_causal_cues(self.n)\n",
    "\n",
    "\n",
    "    def init_words(self):\n",
    "        self.words = []\n",
    "        self.nonCausalWords = []\n",
    "\n",
    "        for label, sentence in zip(self.labels, self.sentences):\n",
    "            if type(sentence) == list:\n",
    "                sentence = ' '.join(sentence)\n",
    "            if \"B-EVENT\" in label: #if sentence is causal\n",
    "                doc = nlp(sentence)\n",
    "                wordsHelp = [token.text for token in doc if not token.is_stop and not token.is_punct and token.pos_ != \"NOUN\" and token.pos_ != \"ADJ\"] \n",
    "                self.words.extend(wordsHelp) #append all words to a list if they are NOT nouns & NOT punctuation & NOT adjectives\n",
    "\n",
    "            else: #if sentence is NOT causal\n",
    "                doc = nlp(sentence)\n",
    "                wordsHelp = [token.text for token in doc if not token.is_stop and not token.is_punct and token.pos_ != \"NOUN\" and token.pos_ != \"ADJ\"] \n",
    "                self.nonCausalWords.extend(wordsHelp)  \n",
    "    \n",
    "    # returns n best causal cues\n",
    "    def get_causal_cues(self, n):\n",
    "        def flatten(lis): #pretty ugly solution but we have to flatten the list since every new sentence adds \"[]\" which Counter can't deal with\n",
    "            for item in lis:\n",
    "                if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "                    for x in flatten(item):\n",
    "                        yield x\n",
    "                else:        \n",
    "                    yield item\n",
    "        \n",
    "        def get_n_lemmata(causal_freq, n):\n",
    "            # sort words\n",
    "            sorted_words = np.array(causal_freq.most_common(len(causal_freq)))[:,0]\n",
    "            converted_return = []\n",
    "            for word in sorted_words:\n",
    "                # lemmatize\n",
    "                doc = nlp(str(word))\n",
    "                word = \" \".join([token.lemma_ for token in doc])\n",
    "                if not word in converted_return:\n",
    "                    converted_return.append(word)\n",
    "                # break if n lemmata found\n",
    "                if len(converted_return)==n:\n",
    "                    break\n",
    "            return converted_return\n",
    "\n",
    "        causal_freq = Counter(self.words)\n",
    "        nonCausal_freq = Counter(self.nonCausalWords)\n",
    "        for word in causal_freq:\n",
    "            causal_freq[word] = causal_freq[word]/(nonCausal_freq[word]+1)\n",
    "        return get_n_lemmata(causal_freq, n)\n",
    "\n",
    "\n",
    "    def predict_causality(self, sentence):\n",
    "        if type(sentence) == list: # convert to str\n",
    "            sentence = ' '.join(sentence)\n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        pattern = [[{\"LEMMA\": cue}] for cue in self.causal_cues]\n",
    "        matcher.add(\"CAUSAL\", pattern)\n",
    "        doc = nlp(sentence)\n",
    "        matches = matcher(doc)\n",
    "        return bool(matches)\n",
    "\n",
    "\n",
    "    # Find best value for n given a testset and initialize causal cues according to best n\n",
    "    def init_causal_cues_best_n(self, test_sentences, test_labels, step_size=20):\n",
    "        new_labels = []\n",
    "        for label in test_labels:\n",
    "            if \"B-EVENT\" in label:\n",
    "                new_labels.append(1)\n",
    "            else:\n",
    "                new_labels.append(0)\n",
    "\n",
    "        old_f1 = 0\n",
    "        f1 = 0\n",
    "        n = 0\n",
    "        while f1 >= old_f1:\n",
    "            n = n+step_size\n",
    "            predictions = []\n",
    "\n",
    "            # predict\n",
    "            self.causal_cues = self.get_causal_cues(n)\n",
    "            for sentence, l in zip(test_sentences, test_labels):\n",
    "                p = self.predict_causality(sentence)\n",
    "                predictions.append(p)\n",
    "\n",
    "            # evaluate\n",
    "            old_f1 = f1\n",
    "            tp = sum([int(p) == 1 and int(l) == 1 for p, l in zip(predictions, new_labels)])\n",
    "            fp = sum([int(p) == 1 and int(l) == 0 for p, l in zip(predictions, new_labels)])\n",
    "            fn = sum([int(p) == 0 and int(l) == 1 for p, l in zip(predictions, new_labels)])\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "        self.f1 = old_f1\n",
    "        self.n = n-20\n",
    "        self.causal_cues = self.get_causal_cues(self.n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cause', 'associate', 'lead', 'increase', 'include', 'result', 'relate', 'AGEP', 'find', 'know', 'commonly', 'occur', 'hht', 'call', 'show', 'Haiti', 'usually', 'silica', 'HLA', '10', 'enamel', 'think', 'develop', 'uroporphyrinogen', 'identify', 'especially', 'TLE', 'approximately', 'directly', 'generally', 'extremely', 'particularly', '1', 'additionally', 'jme', 'affect', 'mg', 'typically', 'underlie', 'and/or', 'give', 'contribute', '2', 'induce', 'SJS', 'receive', 'characterize', 'trigger', 'see', '24', 'hepatitis', 'observe', 'introduce', 'pct', '90', 'tend', 'threaten', 'believe', 'describe', 'UROD', 'leave', 'abnormally', 'relatively', 'dust', 'suggest', 'lose', 'HSAN', 'AVM', 'later', 'prolong', 'make', 'follow', 'establish', 'reduce', 'note', 'university', 'significantly', 'potentially', 'eventually', '50', 'ACVRL1', 'consist', '14', 'remove', 'take', 'suspect', 'early', 'purport', 'question', 'lobe', 'latrodectus', 'decrease', 'maintain', 'pass', 'exist', '94', 'Congress', 'Anakin', 'long', 'derive', 'cite', 'Acute', 'present', 'impair', 'swell', 'refer', '3', 'attribute', 'play', 'helicobacter', 'million', 'PHF', 'adie', 'locate', 'contain', 'dissolve', 'hold', 'title', 'polish', 'e.g.']\n"
     ]
    }
   ],
   "source": [
    "is_causal_predictor = is_causal_predictor(train_sentences,train_labels, 120)\n",
    "print(is_causal_predictor.causal_cues)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- Aufzählungen\n",
    "- Präpositionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_prepositions = [\"with\", \"to\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According        O        O        VERB     prep     VBG     \n",
      "two              O        O        NUM      nummod   CD      \n",
      "different        B-EVENT  O        ADJ      amod     JJ      \n",
      "studies          I-EVENT  O        NOUN     pobj     NNS     \n",
      "it               O        O        PRON     nsubj    PRP     \n",
      "seems            O        O        VERB     ROOT     VBZ     \n",
      "plausible        O        O        ADJ      oprd     JJ      \n",
      "that             O        O        SCONJ    mark     IN      \n",
      "the              O        O        DET      det      DT      \n",
      "Pohang           O        B-EVENT  PROPN    compound NNP     \n",
      "earthquake       O        I-EVENT  NOUN     nsubjpass NN      \n",
      "was              O        O        AUX      auxpass  VBD     \n",
      "induced          O        O        VERB     ccomp    VBN     \n",
      "by               O        O        ADP      agent    IN      \n",
      "EGS              O        B-EVENT  PROPN    compound NNP     \n",
      "operations       O        I-EVENT  NOUN     pobj     NNS     \n",
      ".                O        O        PUNCT    punct    .       \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"35916cd4f8104c018ad37cb8df30e337-0\" class=\"displacy\" width=\"2850\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">According</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">two</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">different</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">studies</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">seems</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">plausible</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Pohang</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">earthquake</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">induced</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">EGS</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">operations .</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 925.0,2.0 925.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-3\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,354.0 L578.0,342.0 562.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oprd</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,89.5 2145.0,89.5 2145.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,177.0 1790.0,177.0 1790.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,177.0 2140.0,177.0 2140.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-10\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,354.0 L1987,342.0 2003,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-11\" stroke-width=\"2px\" d=\"M945,352.0 C945,2.0 2150.0,2.0 2150.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2150.0,354.0 L2158.0,342.0 2142.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-12\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,264.5 2310.0,264.5 2310.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">agent</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2310.0,354.0 L2318.0,342.0 2302.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-13\" stroke-width=\"2px\" d=\"M2520,352.0 C2520,264.5 2660.0,264.5 2660.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2520,354.0 L2512,342.0 2528,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-35916cd4f8104c018ad37cb8df30e337-0-14\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,177.0 2665.0,177.0 2665.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-35916cd4f8104c018ad37cb8df30e337-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2665.0,354.0 L2673.0,342.0 2657.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_3(sentence):\n",
    "\n",
    "    def compound_handler(token):\n",
    "        for child in token.children:\n",
    "            if child.dep_ in  [\"amod\",\"compound\",\"det\",\"poss\"]:\n",
    "                predictions[child.i] = \"B-EVENT\"\n",
    "                compound_handler(child)\n",
    "            if child.dep_ in  [\"prep\"]:\n",
    "                predictions[child.i] = \"B-EVENT\"\n",
    "                for prep_child in child.children:\n",
    "                    object_handler(prep_child)\n",
    "\n",
    "    def conj_handler(token):\n",
    "        if token.dep_ in [\"conj\"]:\n",
    "            predictions[token.i] = \"B-EVENT\"\n",
    "            compound_handler(token)\n",
    "        if token.dep_ in [\"cc\"]:\n",
    "            compound_handler(token)\n",
    "        if doc[token.i - 1].text == \"-\":\n",
    "            x = doc[token.i - 2].dep_\n",
    "            if doc[token.i - 2].dep_ == \"amod\":\n",
    "                y = token.i - 1\n",
    "                predictions[token.i - 1] = \"B-EVENT\"\n",
    "                predictions[token.i - 2] = \"B-EVENT\"\n",
    "        # find whole conjunction\n",
    "        for child in token.children:\n",
    "            conj_handler(child)\n",
    "\n",
    "    def object_handler(token):\n",
    "        if token.dep_ in [\"dobj\", \"pobj\", \"nsubj\", \"nsubjpass\"] and token.pos_ not in [\"PRON\"]:\n",
    "            predictions[token.i] = \"B-EVENT\"\n",
    "            compound_handler(token)\n",
    "\n",
    "            for child in token.children:\n",
    "                if child.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "                    predictions[child.i] = \"B-EVENT\"\n",
    "                conj_handler(token)\n",
    "\n",
    "    def cleanup():\n",
    "        for i, token in enumerate(predictions):\n",
    "            if token == \"B-EVENT\" or token == \"I-EVENT\":\n",
    "                try:\n",
    "                    if predictions[i+1] == \"B-EVENT\":\n",
    "                        predictions[i+1] = \"I-EVENT\"\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    doc = Doc(nlp.vocab, words=sentence)\n",
    "    doc = nlp(doc)\n",
    "    predictions = [\"O\"] * len(sentence)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"ROOT\", \"advcl\", \"relcl\"]:\n",
    "            for child in token.children:\n",
    "                # root-child is object?\n",
    "                object_handler(child)\n",
    "                # root-child is prep\n",
    "                if child.dep_ in [\"prep\", \"agent\"]:\n",
    "                    for prep_child in child.children:\n",
    "                        # prep-child is object?\n",
    "                        object_handler(prep_child)\n",
    "\n",
    "        if token.dep_ == \"acl\":\n",
    "            for child in token.children:\n",
    "                object_handler(child)\n",
    "                if child.dep_ == \"agent\":\n",
    "                    for agent_child in child.children:\n",
    "                        object_handler(agent_child)\n",
    "                \n",
    "            for parent in token.ancestors:\n",
    "                object_handler(parent)\n",
    "\n",
    "    cleanup()\n",
    "    return predictions\n",
    "\n",
    "idx = 0\n",
    "sentence = sentences[idx]\n",
    "doc = Doc(nlp.vocab, words=sentence)\n",
    "doc = nlp(doc)\n",
    "iterator = zip(doc, predict_3(sentences[idx]), labels[idx])\n",
    "for token, pred_3, label in iterator:\n",
    "    print(f\"{token.text :<16} {pred_3 :<8} {label :<8} {token.pos_ :<8} {token.dep_:<8} {token.tag_:<8}\")\n",
    "\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relative clause modifier'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"relcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_events(sentence, is_causal_predictor):\n",
    "    causal_sentence = is_causal_predictor.predict_causality(sentence)\n",
    "    if causal_sentence:\n",
    "        return predict_3(sentence)\n",
    "    else:\n",
    "        return [\"O\"] * len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 94/94 [00:00<00:00, 155.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       EVENT       0.30      0.38      0.34       294\n",
      "\n",
      "   micro avg       0.30      0.38      0.34       294\n",
      "   macro avg       0.30      0.38      0.34       294\n",
      "weighted avg       0.30      0.38      0.34       294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_1 = [predict_3(sentence) for sentence in tqdm.tqdm(test_sentences)]\n",
    "print(classification_report(test_labels, predictions_1, scheme=scheme.IOB2, mode=\"strict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 94/94 [00:00<00:00, 142.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       EVENT       0.30      0.38      0.34       294\n",
      "\n",
      "   micro avg       0.30      0.38      0.34       294\n",
      "   macro avg       0.30      0.38      0.34       294\n",
      "weighted avg       0.30      0.38      0.34       294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_1 = [predict_3(sentence) for sentence in tqdm.tqdm(test_sentences)]\n",
    "print(classification_report(test_labels, predictions_1, scheme=scheme.IOB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT  --  root\n",
      "acl  --  clausal modifier of noun (adjectival clause)\n",
      "acomp  --  adjectival complement\n",
      "advcl  --  adverbial clause modifier\n",
      "advmod  --  adverbial modifier\n",
      "agent  --  agent\n",
      "amod  --  adjectival modifier\n",
      "appos  --  appositional modifier\n",
      "attr  --  attribute\n",
      "aux  --  auxiliary\n",
      "auxpass  --  auxiliary (passive)\n",
      "case  --  case marking\n",
      "cc  --  coordinating conjunction\n",
      "ccomp  --  clausal complement\n",
      "compound  --  compound\n",
      "conj  --  conjunct\n",
      "csubj  --  clausal subject\n",
      "csubjpass  --  clausal subject (passive)\n",
      "dative  --  dative\n",
      "dep  --  unclassified dependent\n",
      "det  --  determiner\n",
      "dobj  --  direct object\n",
      "expl  --  expletive\n",
      "intj  --  interjection\n",
      "mark  --  marker\n",
      "meta  --  meta modifier\n",
      "neg  --  negation modifier\n",
      "nmod  --  modifier of nominal\n",
      "npadvmod  --  noun phrase as adverbial modifier\n",
      "nsubj  --  nominal subject\n",
      "nsubjpass  --  nominal subject (passive)\n",
      "nummod  --  numeric modifier\n",
      "oprd  --  object predicate\n",
      "parataxis  --  parataxis\n",
      "pcomp  --  complement of preposition\n",
      "pobj  --  object of preposition\n",
      "poss  --  possession modifier\n",
      "preconj  --  pre-correlative conjunction\n",
      "predet  --  None\n",
      "prep  --  prepositional modifier\n",
      "prt  --  particle\n",
      "punct  --  punctuation\n",
      "quantmod  --  modifier of quantifier\n",
      "relcl  --  relative clause modifier\n",
      "xcomp  --  open clausal complement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'predet' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for label in nlp.get_pipe(\"parser\").labels:\n",
    "    print(label, \" -- \", spacy.explain(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These            B-EVENT  O\n",
      "stereotype       I-EVENT  B-EVENT\n",
      "-                O        I-EVENT\n",
      "based            O        I-EVENT\n",
      "expectations     O        I-EVENT\n",
      "may              O        O\n",
      "lead             O        O\n",
      "to               O        O\n",
      "self             O        B-EVENT\n",
      "-                O        I-EVENT\n",
      "fulfilling       O        I-EVENT\n",
      "prophecies       O        I-EVENT\n",
      ",                O        O\n",
      "in               O        O\n",
      "which            O        O\n",
      "one              O        O\n",
      "'s               O        O\n",
      "inaccurate       O        O\n",
      "expectations     O        O\n",
      "about            O        O\n",
      "a                B-EVENT  O\n",
      "person           I-EVENT  O\n",
      "'s               I-EVENT  O\n",
      "behavior         O        O\n",
      ",                O        O\n",
      "through          B-EVENT  O\n",
      "social           O        O\n",
      "interaction      B-EVENT  O\n",
      ",                I-EVENT  O\n",
      "prompt           I-EVENT  O\n",
      "that             I-EVENT  O\n",
      "person           I-EVENT  O\n",
      "to               I-EVENT  O\n",
      "act              I-EVENT  O\n",
      "in               I-EVENT  O\n",
      "stereotype       O        O\n"
     ]
    }
   ],
   "source": [
    "def print_prediction(sentence, prediction, labels):\n",
    "    for token, pred, label in zip(sentence, prediction, labels):\n",
    "        print(f\"{token :<16} {pred :<8} {label}\")\n",
    "\n",
    "idx = 11\n",
    "print_prediction(sentences[idx], predictions_1[idx], labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
