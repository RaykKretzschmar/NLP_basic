{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "from tqdm import autonotebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"./data/teaching-dataset/sentence_classification_text_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"input.txt\") as f:\n",
    "        sentences = f.read().decode(\"utf-8\").splitlines()\n",
    "with Path(\"./data/teaching-dataset/sentence_classification_references_train.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"references.txt\") as f:\n",
    "        labels = f.read().decode(\"utf-8\").splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Herbal medications, spider bites, iopamidol (used for radiocontrast), lacquers, mercury, psoralen (combined with ultraviolet A to treat psoriasis), and xenobiotics have been associated with the development of AGEP in case reports.\n",
      "1 The jar from the fall had caused a subdural hematoma on the right front side of my brain that shows up in the CT.\n",
      "1 It's very rewarding and I get a great deal of enjoyment and satisfaction from mentoring.\n",
      "1 The video then shows the damage caused by the aircraft as it hit the north tower, follows the disintegrating plane through the interior, and then shows the airplane metal, ignited fuel, dust and smoke exiting the building on the opposite side.\n",
      "0 It has been assumed that the quench starts at the middle cross-section of the magnet.\n",
      "0 Her diamonds are locked in a safe deposit box.\n",
      "0 A large marble was dropped into the bowl.\n",
      "1 Relatives of the prisoners gathered outside the facility to discover the fate of the incarcerated, eventually leading to clashes with the police.\n",
      "1 Preliminary experiments seemed to support this idea in that the quenches produced the predicted high vortex-densities.\n",
      "1 While the high maternal mortality rate in Haiti can be attributed to the fact that women in developing countries tend to have on average more pregnancies than those in developed countries, factors that play a much larger role include poverty, distance, and inadequate services, all of which are negative impacts of structural violence.\n"
     ]
    }
   ],
   "source": [
    "for label, sentence in zip(labels[:10], sentences[:10]):\n",
    "    print(label, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('caused', 486), ('cause', 110), ('associated', 42), ('resulted', 40), ('causes', 40), ('common', 38), ('triggered', 37), ('causing', 33), ('comes', 32), ('lead', 32), ('include', 31), ('leading', 29), ('increased', 29), ('high', 28), ('severe', 27), ('found', 25), ('like', 24), ('large', 24), ('generated', 23), ('produced', 22)]\n"
     ]
    }
   ],
   "source": [
    "#count most common words in sentences that have causal relationship\n",
    "from collections import Counter\n",
    "from collections.abc import Iterable\n",
    "\n",
    "# from: https://stackoverflow.com/questions/17485747/how-to-convert-a-nested-list-into-a-one-dimensional-list-in-python\n",
    "def flatten(lis): #pretty ugly solution but we have to flatten the list since every new sentence adds \"[]\" which Counter can't deal with\n",
    "     for item in lis:\n",
    "         if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "             for x in flatten(item):\n",
    "                 yield x\n",
    "         else:        \n",
    "             yield item\n",
    "\n",
    "                \n",
    "words = []\n",
    "\n",
    "for label, sentence in zip(labels, sentences):\n",
    "    if label == \"1\": #if sentence is causal\n",
    "        doc = nlp(sentence)\n",
    "        wordsHelp = [token.text\n",
    "         for token in doc\n",
    "         if not token.is_stop and not token.is_punct and token.pos_ != \"NOUN\"] #append all words to a list if they are NOT nouns & not punctuation\n",
    "        words.append(wordsHelp)\n",
    "        \n",
    "# five most common tokens\n",
    "word_freq = Counter(flatten(words))\n",
    "common_words = word_freq.most_common(20)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herbal ADJ amod\n",
      "medications NOUN nsubjpass\n",
      ", PUNCT punct\n",
      "spider NOUN compound\n",
      "bites NOUN appos\n",
      ", PUNCT punct\n",
      "iopamidol PROPN conj\n",
      "( PUNCT punct\n",
      "used VERB parataxis\n",
      "for ADP prep\n",
      "radiocontrast NOUN pobj\n",
      ") PUNCT punct\n",
      ", PUNCT punct\n",
      "lacquers NOUN nsubjpass\n",
      ", PUNCT punct\n",
      "mercury NOUN nmod\n",
      ", PUNCT punct\n",
      "psoralen PROPN conj\n",
      "( PUNCT punct\n",
      "combined VERB prep\n",
      "with ADP prep\n",
      "ultraviolet ADJ compound\n",
      "A NOUN pobj\n",
      "to PART aux\n",
      "treat VERB advcl\n",
      "psoriasis NOUN dobj\n",
      ") PUNCT punct\n",
      ", PUNCT punct\n",
      "and CCONJ cc\n",
      "xenobiotics NOUN conj\n",
      "have AUX aux\n",
      "been AUX auxpass\n",
      "associated VERB ROOT\n",
      "with ADP prep\n",
      "the DET det\n",
      "development NOUN pobj\n",
      "of ADP prep\n",
      "AGEP PROPN pobj\n",
      "in ADP prep\n",
      "case NOUN compound\n",
      "reports VERB pobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sentences[0])\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_cues = [\"cause\", \"because\", \"since\", \"due to\", \"causes\"]\n",
    "\n",
    "for words, counts in common_words:\n",
    "    causal_cues.append(str(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Improvements\n",
    "- co-occurence frequencies\n",
    "- patterns in syntactic / dependency trees\n",
    "- causal verbs / causal phrases\n",
    "- lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(sentence, causal_cues):\n",
    "#     doc = nlp(sentence)\n",
    "#     for token in doc:\n",
    "#         if token.text.lower() in causal_cues:\n",
    "#             return 1\n",
    "#     return 0\n",
    "\n",
    "def predict(sentence, causal_cues):\n",
    "    # matcher can be found at https://spacy.io/api/matcher\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    pattern = [[{\"LEMMA\": cue}] for cue in causal_cues]\n",
    "    matcher.add(\"CAUSAL\", pattern)\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    matches = matcher(doc)\n",
    "    return bool(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f1d5eaa7d1492a99e0e88d0a368e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "for sentence in tqdm.tqdm(sentences):\n",
    "    predictions.append(predict(sentence, causal_cues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.87\n",
      "Recall: 0.57\n",
      "F1: 0.69\n",
      "Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "tp = sum([int(p) == 1 and int(l) == 1 for p, l in zip(predictions, labels)])\n",
    "fp = sum([int(p) == 1 and int(l) == 0 for p, l in zip(predictions, labels)])\n",
    "tn = sum([int(p) == 0 and int(l) == 0 for p, l in zip(predictions, labels)])\n",
    "fn = sum([int(p) == 0 and int(l) == 1 for p, l in zip(predictions, labels)])\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"./data/teaching-dataset/sentence_classification_text_test.zip\").open(\"rb\") as file:\n",
    "    zip_file = ZipFile(file)\n",
    "    with zip_file.open(\"input.txt\") as f:\n",
    "        test_sentences = f.read().decode(\"utf-8\").splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172a0ff102784d9381edbe4f9d823606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/840 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = []\n",
    "for sentence in tqdm.tqdm(test_sentences):\n",
    "    test_predictions.append(predict(sentence, causal_cues))\n",
    "Path(\"predictions.txt\").write_text(\"\\n\".join(map(str, test_predictions)));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
